{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3df7b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json, col\n",
    "from pyspark.sql.types import StructType, StringType, IntegerType\n",
    "\n",
    "# SparkSession z Kafka\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"StreamingToParquet\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Schemat danych JSON\n",
    "schema = StructType() \\\n",
    "    .add(\"id\", IntegerType()) \\\n",
    "    .add(\"name\", StringType()) \\\n",
    "    .add(\"message\", StringType())\n",
    "\n",
    "# Wczytanie danych ze strumienia Kafka\n",
    "df = spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka_streaming_lab:9092\") \\\n",
    "    .option(\"subscribe\", \"spark-lab3-topic\") \\\n",
    "    .option(\"startingOffsets\", \"latest\") \\\n",
    "    .load()\n",
    "\n",
    "# Parsowanie JSON\n",
    "parsed = df.selectExpr(\"CAST(value AS STRING)\") \\\n",
    "    .select(from_json(col(\"value\"), schema).alias(\"data\")) \\\n",
    "    .select(\"data.*\")\n",
    "\n",
    "# Zapis do pliku Parquet\n",
    "query = parsed.writeStream \\\n",
    "    .format(\"parquet\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .option(\"path\", \"/home/coder/project/parquet-output\") \\\n",
    "    .option(\"checkpointLocation\", \"/home/coder/project/checkpoints/parquet\") \\\n",
    "    .start()\n",
    "\n",
    "query.awaitTermination()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
